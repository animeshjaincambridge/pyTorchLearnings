{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "w = torch.tensor((1.0), requires_grad = True)\n",
    "\n",
    "# Fwd pass\n",
    "y_hat = w*x\n",
    "\n",
    "loss = (y_hat - y)**2\n",
    "\n",
    "# Bwd pass\n",
    "loss.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Manual (numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch1:w = 1.200, loss = 30.00000000\n",
      "epoch2:w = 1.680, loss = 4.79999924\n",
      "epoch3:w = 1.872, loss = 0.76800019\n",
      "epoch4:w = 1.949, loss = 0.12288000\n",
      "epoch5:w = 1.980, loss = 0.01966083\n",
      "Prediction after training: f(5) = 9.898\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# f = w* x\n",
    "# f = 2*x\n",
    "\n",
    "x = np.array([1,2,3,4], dtype=np.float32)\n",
    "y = np.array([2,4,6,8], dtype=np.float32)\n",
    "\n",
    "w = 0.0\n",
    "\n",
    "# Model predict\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "# loss MSE\n",
    "def loss(y, y_prediction):\n",
    "    return((y_prediction - y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = J = 1/N (wx-y)**2\n",
    "# dJ/dw = 1/N 2*x (wx-y)\n",
    "def gradient(x,y,y_prediction):\n",
    "    return np.dot(2*x, y_prediction- y).mean()\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')    \n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iter = 5\n",
    "\n",
    "for epoch in range(n_iter):\n",
    "#     forward\n",
    "    y_pred = forward(x)\n",
    "    \n",
    "#     loss\n",
    "    l = loss(y, y_pred)\n",
    "    \n",
    "#     grad\n",
    "    dw = gradient(x,y,y_pred)\n",
    "    \n",
    "#     update weight\n",
    "    w -= learning_rate * dw\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f'epoch{epoch+1}:w = {w:.3f}, loss = {l:0.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent torch_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch1:w = 0.300, loss = 30.00000000\n",
      "epoch11:w = 1.665, loss = 1.16278565\n",
      "epoch21:w = 1.934, loss = 0.04506890\n",
      "epoch31:w = 1.987, loss = 0.00174685\n",
      "epoch41:w = 1.997, loss = 0.00006770\n",
      "epoch51:w = 1.999, loss = 0.00000262\n",
      "epoch61:w = 2.000, loss = 0.00000010\n",
      "epoch71:w = 2.000, loss = 0.00000000\n",
      "epoch81:w = 2.000, loss = 0.00000000\n",
      "epoch91:w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# f = w*x, w=2\n",
    "\n",
    "x = torch.tensor([1,2,3,4], dtype = torch.float32)\n",
    "y = torch.tensor([2,4,6,8], dtype = torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype= torch.float32, requires_grad = True)\n",
    "\n",
    "\n",
    "# forward pass\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "def loss(y, y_prediction):\n",
    "    return ((y_prediction - y)**2).mean()\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iter = 100\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}') \n",
    "\n",
    "for epoch in range(n_iter):\n",
    "    y_pred = forward(x)\n",
    "    \n",
    "    l = loss(y, y_pred)\n",
    "    \n",
    "#     backward pass\n",
    "    l.backward()\n",
    "    \n",
    "#     update weights\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate*w.grad\n",
    "        \n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch{epoch+1}:w = {w:.3f}, loss = {l:0.8f}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch1:w = 0.300, loss = 30.00000000\n",
      "epoch11:w = 1.665, loss = 1.16278565\n",
      "epoch21:w = 1.934, loss = 0.04506890\n",
      "epoch31:w = 1.987, loss = 0.00174685\n",
      "epoch41:w = 1.997, loss = 0.00006770\n",
      "epoch51:w = 1.999, loss = 0.00000262\n",
      "epoch61:w = 2.000, loss = 0.00000010\n",
      "epoch71:w = 2.000, loss = 0.00000000\n",
      "epoch81:w = 2.000, loss = 0.00000000\n",
      "epoch91:w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# f = w*x, w=2\n",
    "\n",
    "x = torch.tensor([1,2,3,4], dtype = torch.float32)\n",
    "y = torch.tensor([2,4,6,8], dtype = torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype= torch.float32, requires_grad = True)\n",
    "\n",
    "\n",
    "# forward pass\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "# # loss\n",
    "\n",
    "# def loss(y, y_prediction):\n",
    "#     return ((y_prediction - y)**2).mean()\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iter = 100\n",
    "\n",
    "# loss\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr = learning_rate)\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}') \n",
    "\n",
    "for epoch in range(n_iter):\n",
    "    y_pred = forward(x)\n",
    "    \n",
    "    l = loss(y, y_pred)\n",
    "    \n",
    "#     backward pass\n",
    "    l.backward()\n",
    "    \n",
    "#     update weights\n",
    "    optimizer.step()\n",
    "#     with torch.no_grad():\n",
    "#         w -= learning_rate*w.grad\n",
    "        \n",
    "#     w.grad.zero_()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch{epoch+1}:w = {w:.3f}, loss = {l:0.8f}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 1.810\n",
      "epoch1:w = 0.741, loss = 22.21310806\n",
      "epoch11:w = 1.819, loss = 0.57566243\n",
      "epoch21:w = 1.992, loss = 0.01579435\n",
      "epoch31:w = 2.019, loss = 0.00125680\n",
      "epoch41:w = 2.023, loss = 0.00083130\n",
      "epoch51:w = 2.023, loss = 0.00077380\n",
      "epoch61:w = 2.022, loss = 0.00072852\n",
      "epoch71:w = 2.022, loss = 0.00068611\n",
      "epoch81:w = 2.021, loss = 0.00064618\n",
      "epoch91:w = 2.020, loss = 0.00060856\n",
      "Prediction after training: f(5) = 10.041\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# f = w*x, w=2\n",
    "\n",
    "X = torch.tensor([[1],[2],[3],[4]], dtype = torch.float32)\n",
    "Y = torch.tensor([[2],[4],[6],[8]], dtype = torch.float32)\n",
    "\n",
    "# w = torch.tensor(0.0, dtype= torch.float32, requires_grad = True)\n",
    "\n",
    "X_test = torch.tensor([5], dtype = torch.float32)\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "# model = nn.Linear(input_size, output_size)\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        \n",
    "        #define layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "        \n",
    "model = LinearRegression(input_size, output_size)        \n",
    "\n",
    "# # forward pass\n",
    "# def forward(x):\n",
    "#     return w*x\n",
    "\n",
    "learning_rate = 0.01\n",
    "n_iter = 100\n",
    "\n",
    "# loss\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}') \n",
    "\n",
    "for epoch in range(n_iter):\n",
    "    y_pred = model(X)\n",
    "#     y_pred = forward(x)\n",
    "    \n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "#     backward pass\n",
    "    l.backward()\n",
    "    \n",
    "#     update weights\n",
    "    optimizer.step()\n",
    "#     with torch.no_grad():\n",
    "#         w -= learning_rate*w.grad\n",
    "        \n",
    "#     w.grad.zero_()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f'epoch{epoch+1}:w = {w[0][0].item():.3f}, loss = {l:0.8f}')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 4, #features: 1\n",
      "Prediction before training: f(5) = 2.293\n",
      "epoch  1 : w =  0.7221152782440186  loss =  tensor(18.2752, grad_fn=<MseLossBackward0>)\n",
      "epoch  11 : w =  1.7039498090744019  loss =  tensor(0.4894, grad_fn=<MseLossBackward0>)\n",
      "epoch  21 : w =  1.864549994468689  loss =  tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "epoch  31 : w =  1.8929768800735474  loss =  tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "epoch  41 : w =  1.9000672101974487  loss =  tensor(0.0143, grad_fn=<MseLossBackward0>)\n",
      "epoch  51 : w =  1.9036511182785034  loss =  tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
      "epoch  61 : w =  1.906598687171936  loss =  tensor(0.0127, grad_fn=<MseLossBackward0>)\n",
      "epoch  71 : w =  1.9093741178512573  loss =  tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "epoch  81 : w =  1.9120537042617798  loss =  tensor(0.0112, grad_fn=<MseLossBackward0>)\n",
      "epoch  91 : w =  1.9146519899368286  loss =  tensor(0.0106, grad_fn=<MseLossBackward0>)\n",
      "Prediction after training: f(5) = 9.829\n"
     ]
    }
   ],
   "source": [
    "# 1) Design model (input, output, forward pass with different layers)\n",
    "# 2) Construct loss and optimizer\n",
    "# 3) Training loop\n",
    "#       - Forward = compute prediction and loss\n",
    "#       - Backward = compute gradients\n",
    "#       - Update weights\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Linear regression\n",
    "# f = w * x \n",
    "\n",
    "# here : f = 2 * x\n",
    "\n",
    "# 0) Training samples, watch the shape!\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(f'#samples: {n_samples}, #features: {n_features}')\n",
    "# 0) create a test sample\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "\n",
    "# 1) Design Model, the model has to implement the forward pass!\n",
    "# Here we can use a built-in model from PyTorch\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "# we can call this model with samples X\n",
    "# model = nn.Linear(input_size, output_size)\n",
    "\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define diferent layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "\n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "# 2) Define loss and optimizer\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) Training loop\n",
    "for epoch in range(n_iters):\n",
    "    # predict = forward pass with our model\n",
    "    y_predicted = model(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_predicted)\n",
    "\n",
    "    # calculate gradients = backward pass\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero the gradients after updating\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        [w, b] = model.parameters() # unpack parameters\n",
    "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
    "\n",
    "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, loss=4384.6855\n",
      "epoch:20, loss=3271.2812\n",
      "epoch:30, loss=2465.7146\n",
      "epoch:40, loss=1882.2485\n",
      "epoch:50, loss=1459.2300\n",
      "epoch:60, loss=1152.2557\n",
      "epoch:70, loss=929.3032\n",
      "epoch:80, loss=767.2484\n",
      "epoch:90, loss=649.3734\n",
      "epoch:100, loss=563.5771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Prepare data\n",
    "\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples = 100, n_features = 1, noise=20, random_state = 1)\n",
    "\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "\n",
    "y = y.view(y.shape[0],1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "\n",
    "# 1) Model\n",
    "\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 2) Loss and optimiser\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# 3) tarining step\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #forward pass and loss\n",
    "    y_pred = model(X)\n",
    "    loss = criterion(y_pred, y)\n",
    "    \n",
    "    #bwd pass\n",
    "    loss.backward()\n",
    "    \n",
    "    #update\n",
    "    optimizer.step()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1)%10 == 0:\n",
    "        print(f'epoch:{epoch+1}, loss={loss.item():.4f}')\n",
    "        \n",
    "        \n",
    "# plot\n",
    "predicted = model(X).detach().numpy()\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10, loss=0.6587\n",
      "epoch:20, loss=0.5328\n",
      "epoch:30, loss=0.4544\n",
      "epoch:40, loss=0.4012\n",
      "epoch:50, loss=0.3626\n",
      "epoch:60, loss=0.3330\n",
      "epoch:70, loss=0.3096\n",
      "epoch:80, loss=0.2904\n",
      "epoch:90, loss=0.2743\n",
      "epoch:100, loss=0.2607\n",
      "accuracy = 0.8947\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "# from sklearn.preprocessing import StandardScalar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)\n",
    "\n",
    "# Scale\n",
    "\n",
    "sc= StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "\n",
    "# Model\n",
    "# f = wx+b, sigmoid at end\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self,n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        y_predicted = torch.sigmoid(self.linear(X))\n",
    "        return y_predicted\n",
    "    \n",
    "\n",
    "model = LogisticRegression(n_features)\n",
    "\n",
    "\n",
    "# 2) Loss and optimizer\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training step\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    \n",
    "    #bwd pass\n",
    "    loss.backward()\n",
    "    \n",
    "    #updates\n",
    "    optimizer.step()\n",
    "    \n",
    "    #zero grad\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch+1)%10 == 0:\n",
    "        print(f'epoch:{epoch+1}, loss={loss.item():.4f}')\n",
    "        \n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred_cls = y_pred.round()\n",
    "    \n",
    "    acc = y_pred_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    \n",
    "print(f'accuracy = {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03] [1.] <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "tensor([1.4230e+02, 1.7100e+01, 2.4300e+01, 1.5600e+02, 1.2700e+03, 2.8000e+01,\n",
      "        3.0600e+01, 2.8000e+00, 2.2900e+01, 5.6400e+01, 1.0400e+01, 3.9200e+01,\n",
      "        1.0650e+04]) tensor([1.]) <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor([[1.1620e+02, 1.9900e+01, 2.2800e+01, 1.8000e+02, 9.8000e+02, 3.0200e+01,\n",
      "         2.2600e+01, 1.7000e+00, 1.3500e+01, 3.2500e+01, 1.1600e+01, 2.9600e+01,\n",
      "         3.4500e+03],\n",
      "        [1.3680e+02, 1.8300e+01, 2.3600e+01, 1.7200e+02, 1.0400e+03, 2.4200e+01,\n",
      "         2.6900e+01, 4.2000e+00, 1.9700e+01, 3.8400e+01, 1.2300e+01, 2.8700e+01,\n",
      "         9.9000e+03],\n",
      "        [1.3050e+02, 2.0500e+01, 3.2200e+01, 2.5000e+02, 1.2400e+03, 2.6300e+01,\n",
      "         2.6800e+01, 4.7000e+00, 1.9200e+01, 3.5800e+01, 1.1300e+01, 3.2000e+01,\n",
      "         8.3000e+03],\n",
      "        [1.2370e+02, 1.2100e+01, 2.5600e+01, 1.8100e+02, 9.8000e+02, 2.4200e+01,\n",
      "         2.6500e+01, 3.7000e+00, 2.0800e+01, 4.6000e+01, 1.1900e+01, 2.3000e+01,\n",
      "         6.7800e+03]]) tensor([[2.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.]]) <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "178 45\n",
      "Epoch: 1/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n",
      "Epoch: 2/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, transform = None):\n",
    "        #load data\n",
    "        xy = np.loadtxt('/Users/animesh/Downloads/wine.csv', delimiter = \",\", dtype=np.float32, skiprows = 1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        self.x = xy[:,1:]\n",
    "        self.y = xy[:,[0]]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "    \n",
    "class MulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        inputs, target = sample\n",
    "        inputs *= self.factor\n",
    "        \n",
    "        return inputs, target\n",
    "\n",
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels, type(features), type(labels))\n",
    "\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(10)])\n",
    "\n",
    "dataset = WineDataset(transform = composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels, type(features), type(labels))\n",
    "\n",
    "dataloader = DataLoader(dataset = dataset, batch_size = 4, shuffle = True, num_workers = 0)\n",
    "\n",
    "dataiter = iter(dataloader)\n",
    "data = next(dataiter)\n",
    "# data = dataiter.next()\n",
    "features, labels = data\n",
    "print(features, labels, type(features), type(labels))\n",
    "\n",
    "\n",
    "#Dummy training loop\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        #fwd bwd, update\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65900114 0.24243297 0.09856589]\n",
      "tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x), axis = 0)\n",
    "\n",
    "x = np.array([2.0,1.0,0.1])\n",
    "outputs = softmax(x)\n",
    "print(outputs)\n",
    "\n",
    "x = torch.tensor([2.0,1.0,0.1])\n",
    "outputs = torch.softmax(x, dim=0)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1 numpy: 0.3567\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual*np.log(predicted))\n",
    "    return loss\n",
    "\n",
    "# y must be one hot encoded\n",
    "Y = np.array([1,0,0])\n",
    "y_pred_good = np.array([0.7,0.2,0.1])\n",
    "\n",
    "l1 = cross_entropy(Y, y_pred_good)\n",
    "\n",
    "print(f'Loss1 numpy: {l1:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4170299470424652\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "Y = torch.tensor([0])\n",
    "\n",
    "# n_samples x n_classes = 1 x 3\n",
    "\n",
    "y_pred_good = torch.tensor([[2.0,1.0,0.1]])\n",
    "\n",
    "l1 = loss(y_pred_good, Y)\n",
    "\n",
    "print(l1.item())\n",
    "\n",
    "_, prediction1 = torch.max(y_pred_good, 1)\n",
    "print(prediction1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss1:  0.2834\n",
      "Batch Loss2: 1.6418\n",
      "Actual class: tensor([2, 0, 1]), Y_pred1: tensor([2, 0, 1]), Y_pred2: tensor([0, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "Y = torch.tensor([2,0,1])\n",
    "\n",
    "# n_samples x n_classes = 1 x 3\n",
    "\n",
    "\n",
    "Y_pred_good = torch.tensor(\n",
    "    [[0.1, 0.2, 3.9], # predict class 2\n",
    "    [1.2, 0.1, 0.3], # predict class 0\n",
    "    [0.3, 2.2, 0.2]]) # predict class 1\n",
    "Y_pred_bad = torch.tensor(\n",
    "    [[0.9, 0.2, 0.1],\n",
    "    [0.1, 0.3, 1.5],\n",
    "    [1.2, 0.2, 0.5]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f'Batch Loss1:  {l1.item():.4f}')\n",
    "print(f'Batch Loss2: {l2.item():.4f}')\n",
    "\n",
    "# get predictions\n",
    "_, predictions1 = torch.max(Y_pred_good, 1)\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(f'Actual class: {Y}, Y_pred1: {predictions1}, Y_pred2: {predictions2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1/2, step 100/600, loss = 0.4565\n",
      "epochs 1/2, step 200/600, loss = 0.3749\n",
      "epochs 1/2, step 300/600, loss = 0.2957\n",
      "epochs 1/2, step 400/600, loss = 0.2399\n",
      "epochs 1/2, step 500/600, loss = 0.2697\n",
      "epochs 1/2, step 600/600, loss = 0.2947\n",
      "epochs 2/2, step 100/600, loss = 0.1793\n",
      "epochs 2/2, step 200/600, loss = 0.3308\n",
      "epochs 2/2, step 300/600, loss = 0.0877\n",
      "epochs 2/2, step 400/600, loss = 0.1434\n",
      "epochs 2/2, step 500/600, loss = 0.1456\n",
      "epochs 2/2, step 600/600, loss = 0.0691\n",
      "95.64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "# import numoy as np\n",
    "\n",
    "#device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Hyperparameters\n",
    "input_size = 784 #28*28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "#MNIST \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train =True, transform = transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train =False, transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = next(examples)\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(samples[i][0], cmap = 'gray')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# loss optimzer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training loop\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #fwd pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #bwd\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1)%100 == 0:\n",
    "            print(f'epochs {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
    "            \n",
    "            \n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        #values, index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        \n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    acc = 100.0*n_correct/n_samples\n",
    "    \n",
    "    print(acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# device conifg\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "# hyper parameters\n",
    "num_epochs = 4\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "# dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transfroms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root'./data', train = True, transform = transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root'./data', train = False, transform = transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle=False)\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self)__init__()\n",
    "        self.conv1 = nn.conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = nn.optim.SGD(model_parameters(), lr = learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        \n",
    "        #fwd pass\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        #bwd pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backwards()\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in ./opt/anaconda3/lib/python3.7/site-packages (2.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard) (0.33.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard) (0.10.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard) (41.4.0)\n",
      "Requirement already satisfied: six>=1.10.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard) (1.12.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard) (2.22.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard) (1.21.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard) (0.16.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard) (1.17.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard) (3.13.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard) (1.31.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./opt/anaconda3/lib/python3.7/site-packages (from tensorboard) (1.7.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./opt/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in ./opt/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard) (0.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./opt/anaconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in ./opt/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata->markdown>=2.6.8->tensorboard) (7.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'example_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4732664fd67f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mimg_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'example_data' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sys\n",
    "\n",
    "writer = SummaryWriter(\"runs/mnist\")\n",
    "# import numoy as np\n",
    "\n",
    "#device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Hyperparameters\n",
    "input_size = 784 #28*28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "#MNIST \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train =True, transform = transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train =False, transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = next(examples)\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(samples[i][0], cmap = 'gray')\n",
    "    \n",
    "# plt.show()\n",
    "img_grid = torchvision.utils.make_grid(example_data)\n",
    "writer.add_image('mnist_images', img_grid)\n",
    "\n",
    "writer.close()\n",
    "sys.exit()\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# loss optimzer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training loop\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #fwd pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #bwd\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1)%100 == 0:\n",
    "            print(f'epochs {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
    "            \n",
    "            \n",
    "# test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        #values, index\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        \n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    acc = 100.0*n_correct/n_samples\n",
    "    \n",
    "    print(acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-2-36ce4a8e0f14>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-36ce4a8e0f14>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir = runs\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": [
    "tensorboard --logdir = runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
